{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic('matplotlib inline')\n",
    "get_ipython().magic('reload_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')\n",
    "from anchor_check import *\n",
    "from cloth_analysis import *\n",
    "# import sys\n",
    "# default_stdout = sys.stdout\n",
    "# sys.stdout = open('../log/log_prepare_cloth.txt', 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create thumbnail for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_center_dict = pickle.load(open('../data/anchor_center_dict_all.pkl', 'rb'))\n",
    "# storage = StorageBackend.make_from_config(StorageConfig.make_gcs_config('esper'))\n",
    "# video_list = sorted(anchor_center_dict)\n",
    "# random.shuffle(video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "for idx, video in enumerate(video_list):\n",
    "    if len(anchor_center_dict[video]) == 0:\n",
    "        continue\n",
    "    fid = [anchor_center_dict[video][0]['fid']]\n",
    "    video_path = 'tvnews/videos/' + video + '.mp4'\n",
    "    video_file = RandomReadFile(storage, video_path.encode('ascii'))\n",
    "    video = Decoder(video_file)\n",
    "    img = video.retrieve(fid)[0]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    images.append(img)\n",
    "    if idx > 260:\n",
    "        break\n",
    "    print idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = stitch_img_grid(images[:192], num_col=16, size=(192, 256), deform=False)\n",
    "grid = stitch_img_grid(images[:256], num_col=16, size=(144, 256), deform=True)\n",
    "cv2.imwrite(\"../data/cloth/plot/motivation.jpg\", grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = sorted(img_dict)\n",
    "random.shuffle(path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preload all images, pad and resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloth_infer = pickle.load(open('../data/cloth/cloth_all_infer.pkl', 'rb'))\n",
    "# random.shuffle(cloth_infer)\n",
    "# trans = {'video': 0, 'anchor_id': 1, 'path': 2, 'bbox': 3, 'attributes': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloth_dict = pickle.load(open('../data/cloth/newsAnchor_all_data_first.pkl', \"rb\" ))\n",
    "random.shuffle(cloth_dict)\n",
    "trans = {'video': 0, 'anchor_id': 1, 'path': 2, 'detail': 3, 'bbox': 4, 'gender':5, 'attributes': 6, 'feature': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dict = {}\n",
    "img_dir = '../data/cloth/cloth_all_img'\n",
    "for cloth in cloth_dict:\n",
    "    path = cloth[trans['path']]\n",
    "    bbox = cloth[trans['bbox']]\n",
    "    img = cv2.imread(os.path.join(img_dir, path))\n",
    "    if not img is None:\n",
    "        img_pad = pad_image_height(img, bbox, size=(200, 100))\n",
    "        img_dict[path] = img_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_id = 1\n",
    "num_per_class = 500\n",
    "img_dir = '../data/cloth/cloth_all_img'\n",
    "images = []\n",
    "for cloth in cloth_dict:\n",
    "    attributes = cloth[trans['attributes']]\n",
    "    attr = int(attributes[attribute_id])\n",
    "    date, station, show = cloth[trans['detail']]\n",
    "    if len(images) < num_per_class and attr == 8:\n",
    "        path = cloth[trans['path']]\n",
    "#         img_pad = img_dict[path]\n",
    "        bbox = cloth[trans['bbox']]\n",
    "        img = cv2.imread(os.path.join(img_dir, path))\n",
    "        H, W, C = img.shape\n",
    "        if not img is None and 1. * H / W > 1.9:\n",
    "            img_pad = pad_image_height(img, bbox, size=(200, 100))\n",
    "            images.append(img_pad)\n",
    "\n",
    "random.shuffle(images)\n",
    "grid = stitch_img_grid(images, 5, size=(200, 100), deform=False)\n",
    "filename = '../data/cloth/plot/proposal_yellow' + '.jpg'\n",
    "cv2.imwrite(filename, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot average cloth attributes (for report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_class_grid = []\n",
    "titles = []\n",
    "\n",
    "for attribute_id in range(17):\n",
    "    if attribute_id == 14:\n",
    "        continue\n",
    "    \n",
    "    img_dir = '../data/cloth/cloth_all_img'\n",
    "    images_class = [[] for i in range(len(attri_dict[attribute_id]))]\n",
    "    for cloth in cloth_dict:\n",
    "        attributes = cloth[trans['attributes']]\n",
    "        if (attribute_id == 12 or attribute_id == 13) and int(attributes[2]) == 0:\n",
    "            continue\n",
    "        attr = int(attributes[attribute_id])\n",
    "        path = cloth[trans['path']]\n",
    "        img_pad = img_dict[path]\n",
    "        images_class[attr].append(img_pad)\n",
    "\n",
    "    for idx, images in enumerate(images_class):\n",
    "        if len(images) == 0:\n",
    "            continue\n",
    "    #     images_class_grid.append(stitch_img_grid(images, 50, size=None))\n",
    "        # add average\n",
    "        images_class_grid.append(average_image(images, size=None))\n",
    "\n",
    "    for idx, t in enumerate(attri_dict_inv[attribute_id].values()):\n",
    "        if len(images_class[idx]) == 0:\n",
    "            continue\n",
    "        titles.append(t)\n",
    "\n",
    "#     filename = '../data/cloth/plot/average_' + attri_name[attribute_id] + '_report.jpg'\n",
    "filename = '../data/cloth/plot/average_report.jpg'\n",
    "multi_plot(images_class_grid, 15, size=(30, 20), titles=titles, output=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot average cloth attributes (separate gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute_id in range(17):\n",
    "    img_dir = '../data/cloth/cloth_all_img'\n",
    "    images_class_M = [[] for i in range(len(attri_dict[attribute_id]))]\n",
    "    images_class_F = [[] for i in range(len(attri_dict[attribute_id]))]\n",
    "    images_class = [[] for i in range(len(attri_dict[attribute_id]))]\n",
    "    for cloth in cloth_dict:\n",
    "        attributes = cloth[trans['attributes']]\n",
    "        if (attribute_id == 12 or attribute_id == 13) and int(attributes[2]) == 0:\n",
    "            continue\n",
    "        attr = int(attributes[attribute_id])\n",
    "        gender = cloth[trans['gender']]\n",
    "        path = cloth[trans['path']]\n",
    "        img_pad = img_dict[path]\n",
    "        images_class[attr].append(img_pad)\n",
    "        if gender == 'M':\n",
    "            images_class_M[attr].append(img_pad)\n",
    "        elif gender == 'F':\n",
    "            images_class_F[attr].append(img_pad)\n",
    "\n",
    "    images_class_grid = []\n",
    "    for idx, images in enumerate(images_class):\n",
    "#         if len(images) == 0:\n",
    "#             continue\n",
    "    #     images_class_grid.append(stitch_img_grid(images, 50, size=None))\n",
    "        # add average\n",
    "        images_class_grid.append(average_image(images, size=None))\n",
    "        images_class_grid.append(average_image(images_class_M[idx], size=None))\n",
    "        images_class_grid.append(average_image(images_class_F[idx], size=None))\n",
    "\n",
    "    titles = []\n",
    "    for idx, t in enumerate(attri_dict_inv[attribute_id].values()):\n",
    "#         if len(images_class[idx]) == 0:\n",
    "#             continue\n",
    "        titles.append(t + ' All(' + str(len(images_class[idx])) + ')')\n",
    "        titles.append(t + ' Male(' + str(len(images_class_M[idx])) + ')')\n",
    "        titles.append(t + ' Female(' + str(len(images_class_F[idx])) + ')')\n",
    "\n",
    "    filename = '../data/cloth/plot/supply/average_' + attri_name[attribute_id] + '.jpg'\n",
    "    multi_plot(images_class_grid, 3, size=(16, 10*len(attri_dict[attribute_id])), titles=titles, output=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check hair length in summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_id = 15\n",
    "num_per_class = 500\n",
    "img_dir = '../data/cloth/cloth_all_img'\n",
    "images_class = [[] for i in range(len(attri_dict[attribute_id]))]\n",
    "for cloth in cloth_dict:\n",
    "    attributes = cloth[trans['attributes']]\n",
    "    attr = int(attributes[attribute_id])\n",
    "    date, station, show = cloth[trans['detail']]\n",
    "    if len(images_class[attr]) < num_per_class and date[1] >= 7 and date[1] <= 8:\n",
    "        path = cloth[trans['path']]\n",
    "        img_pad = img_dict[path]\n",
    "        images_class[attr].append(img_pad)\n",
    "\n",
    "images_class_grid = []\n",
    "for images in images_class:\n",
    "#         if len(images) == 0:\n",
    "#             continue\n",
    "    images_class_grid.append(stitch_img_grid(images, 30, size=None))\n",
    "    # add average\n",
    "    images_class_grid.append(average_image(images, size=None))\n",
    "\n",
    "titles = []\n",
    "for idx, t in enumerate(attri_dict_inv[attribute_id].values()):\n",
    "    titles.append(t)\n",
    "#         if len(images_class[idx]) == 0:\n",
    "#             continue\n",
    "    titles.append(t)\n",
    "filename = '../data/cloth/plot/average_' + attri_name[attribute_id] + '_5000.jpg'\n",
    "multi_plot(images_class_grid, 5, size=(100, 100), titles=titles, output=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot average male/female host over monthofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_month_M = [[] for i in range(12)]\n",
    "images_month_F = [[] for i in range(12)]\n",
    "\n",
    "num_per_class = 50000\n",
    "img_dir = '../data/cloth/cloth_all_img'\n",
    "for cloth in cloth_dict:\n",
    "    gender = cloth[trans['gender']]\n",
    "    date, station, show = cloth[trans['detail']]\n",
    "    \n",
    "    path = cloth[trans['path']]\n",
    "#         bbox = cloth[trans['bbox']]\n",
    "#         img = cv2.imread(os.path.join(img_dir, path))\n",
    "#         if not img is None:\n",
    "#             img_pad = pad_image_height(img, bbox, size=(200, 100))\n",
    "#             images_class[attr].append(img_pad)\n",
    "    img = img_dict[path]\n",
    "    if gender == 'M' and len(images_month_M) < num_per_class:\n",
    "        images_month_M[date[1]-1].append(img)\n",
    "    elif gender == 'F' and len(images_month_F) < num_per_class:\n",
    "        images_month_F[date[1]-1].append(img)\n",
    "        \n",
    "images_class_grid = []\n",
    "for images in images_month_M:\n",
    "    images_class_grid.append(average_image(images, size=None))\n",
    "for images in images_month_F:\n",
    "    images_class_grid.append(average_image(images, size=None))    \n",
    "\n",
    "titles = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "titles += titles\n",
    "\n",
    "filename = '../data/cloth/plot/report/average_month.jpg'\n",
    "multi_plot(images_class_grid, 12, size=(24, 8), titles=titles, output=filename)\n",
    "\n",
    "# grid = stitch_img_grid(images_class_grid, 12, size=None)\n",
    "# single_plot(grid, size=(16, 16), title='Male/Female averaged by month', output=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot average male/female host over hourofday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_hour_M = [[] for i in range(24)]\n",
    "images_hour_F = [[] for i in range(24)]\n",
    "\n",
    "def get_hour_bin(date):\n",
    "    return (date[3] - 5) % 24\n",
    "\n",
    "num_per_class = 50000\n",
    "img_dir = '../data/cloth/cloth_all_img'\n",
    "for cloth in cloth_dict:\n",
    "    gender = cloth[trans['gender']]\n",
    "    date, station, show = cloth[trans['detail']]\n",
    "    path = cloth[trans['path']]\n",
    "#         bbox = cloth[trans['bbox']]\n",
    "#         img = cv2.imread(os.path.join(img_dir, path))\n",
    "#         if not img is None:\n",
    "#             img_pad = pad_image_height(img, bbox, size=(200, 100))\n",
    "#             images_class[attr].append(img_pad)\n",
    "    img = img_dict[path]\n",
    "    if gender == 'M' and len(images_hour_M) < num_per_class:\n",
    "        images_hour_M[get_hour_bin(date)].append(img)\n",
    "    elif gender == 'F' and len(images_hour_F) < num_per_class:\n",
    "        images_hour_F[get_hour_bin(date)].append(img)\n",
    "        \n",
    "images_class_grid = []\n",
    "for images in images_hour_M:\n",
    "    images_class_grid.append(average_image(images, size=None))\n",
    "for images in images_hour_F:\n",
    "    images_class_grid.append(average_image(images, size=None))    \n",
    "\n",
    "titles = ['{:02d}'.format(i) for i in range(24)]\n",
    "titles += titles\n",
    "\n",
    "filename = '../data/cloth/plot/report/average_hour.jpg'\n",
    "multi_plot(images_class_grid, 24, size=(32, 6), titles=titles, output=filename)\n",
    "\n",
    "# grid = stitch_img_grid(images_class_grid, 24, size=None)\n",
    "# single_plot(grid, size=(32, 16), title='Male/Female averaged by hour', output=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot average male/female host over dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_week_M = [[] for i in range(7)]\n",
    "images_week_F = [[] for i in range(7)]\n",
    "\n",
    "num_per_class = 50000\n",
    "img_dir = '../data/cloth/cloth_all_img'\n",
    "for cloth in cloth_dict:\n",
    "    gender = cloth[trans['gender']]\n",
    "    date, station, show = cloth[trans['detail']]\n",
    "    path = cloth[trans['path']]\n",
    "#         bbox = cloth[trans['bbox']]\n",
    "#         img = cv2.imread(os.path.join(img_dir, path))\n",
    "#         if not img is None:\n",
    "#             img_pad = pad_image_height(img, bbox, size=(200, 100))\n",
    "#             images_class[attr].append(img_pad)\n",
    "    img = img_dict[path]\n",
    "    if gender == 'M' and len(images_week_M) < num_per_class:\n",
    "        images_week_M[get_week_bin(date)].append(img)\n",
    "    elif gender == 'F' and len(images_week_F) < num_per_class:\n",
    "        images_week_F[get_week_bin(date)].append(img)\n",
    "        \n",
    "images_class_grid = []\n",
    "for images in images_week_M:\n",
    "    images_class_grid.append(average_image(images, size=None))\n",
    "for images in images_week_F:\n",
    "    images_class_grid.append(average_image(images, size=None))    \n",
    "# titles = ['Male_M'+str(i) for i in range(1,13) ]\n",
    "# titles += ['Female_M'+str(i) for i in range(1,13) ]\n",
    "\n",
    "filename = '../data/cloth/plot/average_dayofweek_5000.jpg'\n",
    "# multi_plot(images_class_grid, 3, size=(16, 32), titles=titles, output=filename)\n",
    "\n",
    "grid = stitch_img_grid(images_class_grid, 7, size=None)\n",
    "single_plot(grid, size=(16, 16), title='Male/Female averaged by dayofweek', output=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot average single host over dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_center_dict = pickle.load(open('../data/anchor_center_dict_all.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_center_show = group_by_show(anchor_center_dict)\n",
    "\n",
    "for show_name, anchor_center in anchor_center_show.items():\n",
    "    if len(anchor_center) < 500:\n",
    "        continue\n",
    "    # anchor_center = build_anchor_center(anchor_dict_show[show_name])\n",
    "    real_anchors = cluster_real_anchor(anchor_center_show[show_name])\n",
    "    for real_anchor_id in range(len(real_anchors)):\n",
    "        real_anchor = real_anchors[real_anchor_id]\n",
    "\n",
    "        FACE_SIM_THRESH = 0.9\n",
    "        img_dir = '../data/cloth/cloth_all_img/'\n",
    "        images_week = [[] for i in range(7)]\n",
    "        for cloth in cloth_dict:\n",
    "            video = cloth[trans['video']]\n",
    "            anchor_id = cloth[trans['anchor_id']]\n",
    "            date, station, show = cloth[trans['detail']]\n",
    "            if show != show_name:\n",
    "                continue\n",
    "            ## check face with real anchor\n",
    "            ## hack for bad anchor detection result\n",
    "            if anchor_id >= len(anchor_center[video]):\n",
    "                continue\n",
    "            center = anchor_center[video][anchor_id] \n",
    "            if np.linalg.norm(real_anchor - center['feature']) > FACE_SIM_THRESH:\n",
    "                continue\n",
    "\n",
    "            path = cloth[trans['path']]\n",
    "        #         bbox = cloth[trans['bbox']]\n",
    "        #         img = cv2.imread(os.path.join(img_dir, path))\n",
    "        #         if not img is None:\n",
    "        #             img_pad = pad_image_height(img, bbox, size=(200, 100))\n",
    "        #             images_class[attr].append(img_pad)\n",
    "            img = img_dict[path]\n",
    "            images_week[get_week_bin(date)].append(img)\n",
    "\n",
    "        images_class_grid = []\n",
    "        for images in images_week:\n",
    "            images_class_grid.append(average_image(images, size=None))\n",
    "#             images_class_grid.append(stitch_img_grid(images, 10, size=None))\n",
    "        \n",
    "#         titles = [str(i) for i in range(1,8) ]\n",
    "\n",
    "        filename = '../data/cloth/plot/average_dayofweek_' + show_name + '_' + str(real_anchor_id) + '.jpg'\n",
    "#         multi_plot(images_class_grid, 2, size=(50, 150), titles=None, output=filename)\n",
    "\n",
    "        grid = stitch_img_grid(images_class_grid, 7, size=None)\n",
    "        single_plot(grid, size=(16, 16), title=show_name + ' averaged by dayofweek', output=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot heatmap of major color&necktie color on single host over dayofweek "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "anchor_center_show = group_by_show(anchor_center_dict)\n",
    "\n",
    "for show_name, anchor_center in anchor_center_show.items():\n",
    "    if len(anchor_center) < 500:\n",
    "        continue\n",
    "    # anchor_center = build_anchor_center(anchor_dict_show[show_name])\n",
    "    real_anchors = cluster_real_anchor(anchor_center_show[show_name])\n",
    "    for real_anchor_id in range(len(real_anchors)):\n",
    "        real_anchor = real_anchors[real_anchor_id]\n",
    "\n",
    "        FACE_SIM_THRESH = 0.9\n",
    "        img_dir = '../data/cloth/cloth_all_img/'\n",
    "        majorColor_week = [[] for i in range(7)]\n",
    "        tieColor_week = [[] for i in range(7)]\n",
    "        heat_matrix_major = np.zeros((len(attri_dict[1]), 7))\n",
    "        heat_matrix_tie = np.zeros((len(attri_dict[12]), 7))\n",
    "        for cloth in cloth_dict:\n",
    "            video = cloth[trans['video']]\n",
    "            anchor_id = cloth[trans['anchor_id']]\n",
    "            date, station, show = cloth[trans['detail']]\n",
    "            if show != show_name:\n",
    "                continue\n",
    "            ## check face with real anchor\n",
    "            ## hack for bad anchor detection result\n",
    "            if anchor_id >= len(anchor_center[video]):\n",
    "                continue\n",
    "            center = anchor_center[video][anchor_id] \n",
    "            if np.linalg.norm(real_anchor - center['feature']) > FACE_SIM_THRESH:\n",
    "                continue\n",
    "            \n",
    "            attributes = cloth[trans['attributes']]\n",
    "            majorColor_week[get_week_bin(date)].append(attributes[1])\n",
    "            if attributes[2] == 0:\n",
    "                continue\n",
    "            tieColor_week[get_week_bin(date)].append(attributes[12])\n",
    "        \n",
    "        for i in range(len(attri_dict[1])):\n",
    "            for j in range(7):\n",
    "                if len(majorColor_week[j]) == 0:\n",
    "                    heat_matrix_major[i, j] = 0\n",
    "                else:\n",
    "                    heat_matrix_major[i, j] = 1. * majorColor_week[j].count(i) / len(majorColor_week[j])\n",
    "                if len(tieColor_week[j]) == 0:\n",
    "                    heat_matrix_tie[i, j] = 0\n",
    "                else:\n",
    "                    heat_matrix_tie[i, j] = 1. * tieColor_week[j].count(i) / len(tieColor_week[j])\n",
    "#         fig = plt.figure()\n",
    "#         fig.set_figwidth(16)\n",
    "#         plt.subplot(1,2,1)\n",
    "        plt.figure()\n",
    "        y_ticks = attri_dict_inv[1].values()\n",
    "        x_ticks = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "        x_ticks = [x_ticks[i] + ' ({0:d})'.format(len(majorColor_week[i])) for i in range(7)]\n",
    "        ax = sns.heatmap(heat_matrix_major, vmin=0, vmax=1.0, xticklabels=x_ticks, yticklabels=y_ticks)\n",
    "        plt.title(show_name + '   Major color')\n",
    "        filename = '../data/cloth/plot/heatmap_dayofweek_' + show_name + '_' + str(real_anchor_id) + '_majorcolor.png'\n",
    "        plt.savefig(filename)\n",
    "        \n",
    "#         plt.subplot(1,2,2)\n",
    "        plt.figure()\n",
    "        y_ticks = attri_dict_inv[12].values()\n",
    "        x_ticks = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "        x_ticks = [x_ticks[i] + ' ({0:d})'.format(len(tieColor_week[i])) for i in range(7)]\n",
    "        ax = sns.heatmap(heat_matrix_tie, vmin=0, vmax=1.0, xticklabels=x_ticks, yticklabels=y_ticks)\n",
    "        plt.title(show_name + '   Necktie color')\n",
    "        filename = '../data/cloth/plot/heatmap_dayofweek_' + show_name + '_' + str(real_anchor_id) + '_necktiecolor.png'\n",
    "        plt.savefig(filename)\n",
    "        \n",
    "#         plt.show()\n",
    "\n",
    "#         multi_plot(images_class_grid, 2, size=(16, 16), titles=None, output=filename)\n",
    "#         single_plot(, size=(16, 16), title=show_name + ' averaged by dayofweek', output=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot thumbnail of female hosts in different stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_name = 'MSNBC'\n",
    "\n",
    "images = []\n",
    "img_dir = '../data/cloth/cloth_all_img'\n",
    "## check cases when anchor are not showing\n",
    "cnt = 0\n",
    "for cloth in cloth_dict:\n",
    "    detail = cloth[trans['detail']]\n",
    "    if detail[1] != station_name or cloth[trans['gender']] != 'F':\n",
    "        continue\n",
    "    img = cv2.imread(os.path.join(img_dir, cloth[trans['path']]))\n",
    "    H, W, C = img.shape\n",
    "#     bbox = cloth[trans['bbox']]\n",
    "#     img_crop = img[bbox['bbox_y2']+20:, :, :]\n",
    "    img_crop = img[H/2:, :, :]\n",
    "    images.append(img_crop)\n",
    "    cnt +=1\n",
    "    if cnt % 1000 == 0:\n",
    "        print(cnt)\n",
    "    if cnt == 6400:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_sort = sort_images_by_NN(images)\n",
    "grid = stitch_img_grid(images_sort, 80, size=(50, 50), deform=True)\n",
    "cv2.imwrite('../data/cloth/plot/MSNBC_Female_NN.jpg', grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare 3 stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cv2.imread('../data/cloth/plot/CNN_Female_NN.jpg')\n",
    "fox = cv2.imread('../data/cloth/plot/FOXNEWS_Female_NN.jpg')\n",
    "msnbc = cv2.imread('../data/cloth/plot/MSNBC_Female_NN.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(48, 16)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv2.cvtColor(cnn, cv2.COLOR_BGR2RGB))\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.title('CNN')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(cv2.cvtColor(fox, cv2.COLOR_BGR2RGB))\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.title('FOXNEWS')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv2.cvtColor(msnbc, cv2.COLOR_BGR2RGB))\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.title('MSNBC')\n",
    "\n",
    "plt.savefig('../data/cloth/plot/report/anchor_stations_female.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM Cluster on feature map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA first\n",
    "feature_list = [cloth[trans['feature']] for cloth in cloth_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=200)\n",
    "feature_pca = pca.fit_transform(np.array(feature_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "NUM_CLUSTER = 77\n",
    "from sklearn import mixture\n",
    "gmm = mixture.GaussianMixture(n_components=NUM_CLUSTER, covariance_type='diag')\n",
    "gmm.fit(feature_pca)\n",
    "score = gmm.bic(feature_pca)\n",
    "\n",
    "print(time.time() - start, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = gmm.predict(feature_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect samples near cluster centers\n",
    "cluster = []\n",
    "N = feature_pca.shape[0]\n",
    "for c in range(NUM_CLUSTER):\n",
    "    group = [] \n",
    "    center = gmm.means_[c]\n",
    "    for idx in range(N):\n",
    "        if predicted[idx] == c:\n",
    "            group.append(idx)\n",
    "    dist = []\n",
    "    for idx in group:\n",
    "        d = np.linalg.norm(center - feature_pca[idx])\n",
    "        dist.append(d)\n",
    "    group_sort = np.argsort(dist)\n",
    "    group = [ group[idx] for idx in group_sort ]\n",
    "    cluster.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "NUM_PER_CLUSTER = 20\n",
    "NUM_AVERAGE = 10000\n",
    "images = []\n",
    "img_dir = '../data/cloth/cloth_all_img'\n",
    "for c, group in enumerate(cluster):\n",
    "    num_per_cluster = min(NUM_PER_CLUSTER, len(group))\n",
    "    num_average = min(NUM_AVERAGE, len(group))\n",
    "    for idx in range(num_per_cluster):\n",
    "        path = cloth_dict[group[idx]][trans['path']]\n",
    "        bbox = cloth_dict[group[idx]][trans['bbox']]\n",
    "        img = cv2.imread(os.path.join(img_dir, path))\n",
    "        img_pad = pad_image_height(img, bbox)\n",
    "        images.append(img_pad)\n",
    "    for i in range(NUM_PER_CLUSTER - num_per_cluster):\n",
    "        images.append(np.zeros((200, 100, 3)))\n",
    "        \n",
    "grid = stitch_img_grid(images, 200, 100, 20, False, True)\n",
    "cv2.imwrite('../data/cloth/plot/GMM_cluster.jpg', grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
