{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic('matplotlib inline')\n",
    "get_ipython().magic('reload_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')\n",
    "from prepare_cloth import *\n",
    "from anchor_check import *\n",
    "# import sys\n",
    "# default_stdout = sys.stdout\n",
    "# sys.stdout = open('../log/log_prepare_cloth.txt', 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop and collect images from the anchor detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_dict = pickle.load(open('../data/anchor_dict_all.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor_detect import *\n",
    "anchor_dict_clean = clean_anchor_dict(anchor_dict, people_dict)\n",
    "pickle.dump(anchor_dict_clean, open('../data/anchor_dict_all_clean.pkl', \"wb\" ), protocol=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove existed video\n",
    "res_dict = pickle.load(open('../data/cloth/cloth_manifest.pkl', 'rb'))\n",
    "for p in res_dict_clean:\n",
    "    if p[0] in anchor_dict:\n",
    "        del anchor_dict[p[0]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_parallel_memory(anchor_dict, '../data/cloth/cloth_half3_manifest.pkl', 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect tmp result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict2 = []\n",
    "nthread = 32\n",
    "tmp_dict_list = []\n",
    "for i in range(nthread):\n",
    "    tmp_dict_list.append('../tmp/cloth_dict_' + str(i) + '.pkl')\n",
    "\n",
    "for path in tmp_dict_list:\n",
    "    dict_file = Path(path)\n",
    "    if not dict_file.is_file():\n",
    "        continue\n",
    "    res_dict_tmp = pickle.load(open(path, \"rb\" ))\n",
    "    res_dict2.extend(res_dict_tmp)\n",
    "\n",
    "pickle.dump(res_dict2, open('../data/cloth/cloth_half0_manifest2.pkl', \"wb\" ), protocol=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = pickle.load(open('../data/cloth/cloth_manifest.pkl', \"rb\" ))\n",
    "res_dict2 = pickle.load(open('../data/cloth/cloth_half3_manifest.pkl', \"rb\" ))\n",
    "res_dict.extend(res_dict2)\n",
    "print(len(res_dict))\n",
    "# pickle.dump(res_dict, open('../data/cloth/cloth_manifest.pkl', \"wb\" ), protocol=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean repeated result\n",
    "repeate = {}\n",
    "repeate_video = {}\n",
    "res_dict_clean = []\n",
    "cnt = 0\n",
    "for res in res_dict2:\n",
    "    repeate_video[res[0]] = 0\n",
    "    if res[2] in repeate:\n",
    "        print(res[2], res[3], repeate[res[2]])\n",
    "        cnt += 1\n",
    "        pass\n",
    "    else: \n",
    "        repeate[res[2]] = res[3]\n",
    "        res_dict_clean.append(res)\n",
    "print(len(res_dict_clean))\n",
    "print(len(res_dict2))\n",
    "print(len(repeate_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(res_dict_clean, open('../data/cloth/cloth_manifest.pkl', 'wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recollect bbox for cloth_label dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloth_label = pickle.load(open('../data/cloth/newsAnchor_train_manifest.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = {}\n",
    "for label in cloth_label:\n",
    "    video[label[0][0]] = 0\n",
    "video_list = sorted(video)\n",
    "print(len(video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_dict_tmp = {video: anchor_dict[video] for video in video_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_parallel_memory(anchor_dict_tmp, '../tmp/newsAnchor_train_manifest_makeup.pkl', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloth_label_makup = pickle.load(open('../tmp/newsAnchor_train_manifest_makeup.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in cloth_label:\n",
    "    for label in group:\n",
    "        find = False\n",
    "        for makeup in cloth_label_makup:\n",
    "            if makeup[2] == label[2]:\n",
    "                label.append(makeup[3])\n",
    "                find = True\n",
    "                break\n",
    "        if not find:\n",
    "            print(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cloth_label[0][0])\n",
    "test = cloth_label[35][4]\n",
    "img = cv2.imread('../data/cloth/cloth_label/' + test[2])\n",
    "x1 = test[4]['bbox_x1']\n",
    "y1 = test[4]['bbox_y1']\n",
    "x2 = test[4]['bbox_x2']\n",
    "y2 = test[4]['bbox_y2']\n",
    "print(x1, y1, x2, y2)\n",
    "cv2.rectangle(img, (x1, y1), (x2, y2), color=(0,0,255), thickness=3)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct cloth_all_infer (major vote for cloth attribute, include feature_vec, include gendre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_dict = pickle.load(open('../data/anchor_dict_all.pkl', 'rb'))\n",
    "# gender_dict = pickle.load(open('../data/cloth/gender_dict.pkl', 'rb'))\n",
    "# cloth_infer = pickle.load(open('../data/cloth/cloth_all_infer.pkl', \"rb\" ))\n",
    "# feature_dict = pickle.load(open('../data/cloth/cloth_all_feature.pkl', \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_gender_for_anchor(anchor_person, gender_list):\n",
    "    gender = {'F': 0, 'M': 0, 'U': 0}\n",
    "    for p in anchor_person:\n",
    "        candidate = gender_list[p['fid']]\n",
    "        for c in candidate:\n",
    "            if (p['bbox']['bbox_x1'] - c[0]['bbox_x1'] + p['bbox']['bbox_y1'] - c[0]['bbox_y1']) < 1e-5:\n",
    "                gender[c[1]] += 1\n",
    "                break\n",
    "    if gender['F'] + gender['M'] == 0:\n",
    "        print('bad gender')\n",
    "    if gender['F'] > gender['M']:\n",
    "        return 'F'\n",
    "    else:\n",
    "        return 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create structure of [[manifest per anchor]] \n",
    "pid = -1\n",
    "current_video = ''\n",
    "current_anchor = 0\n",
    "cloth_infer_group = []\n",
    "for idx, p in enumerate(cloth_infer):\n",
    "    video = p[0]\n",
    "    anchor_id = p[1]\n",
    "    if video != current_video or anchor_id != current_anchor:\n",
    "        cloth_infer_group.append([])\n",
    "        current_video = video\n",
    "        current_anchor = anchor_id\n",
    "    p.append(feature_dict[idx][1])\n",
    "    cloth_infer_group[-1].append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloth_infer_group[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VOTE = 5\n",
    "MAX_CLASS = 20\n",
    "    \n",
    "cloth_dict = []\n",
    "for pid, p_group in enumerate(cloth_infer_group):\n",
    "    video = p_group[0][0]\n",
    "    anchor_id = p_group[0][1]\n",
    "    ## major vote for cloth attributes\n",
    "    votes = []\n",
    "    num_vote = min(len(p_group), NUM_VOTE)\n",
    "    for i in range(num_vote):\n",
    "        votes.append(p_group[i][4])\n",
    "    votes = np.array(votes).transpose()\n",
    "    major_vote = []\n",
    "    for idx, vote in enumerate(votes):\n",
    "        cnt = np.zeros(MAX_CLASS)\n",
    "        for v in vote:\n",
    "            cnt[int(v)] += 1\n",
    "        major_vote.append(np.argmax(cnt))\n",
    "    ## check bbox to find gender\n",
    "    gender = vote_gender_for_anchor(anchor_dict[video][anchor_id], gender_dict[video])\n",
    "    ## stitch for new item\n",
    "    new_p = p_group[0][:4] + [gender, major_vote, p_group[0][-1]]\n",
    "    cloth_dict.append(new_p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(cloth_dict)\n",
    "pickle.dump(cloth_dict, open('../data/cloth/newsAnchor_all_data.pkl', 'wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random sample image from group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloth_dict = pickle.load(open('../data/cloth/newsAnchor_all_data_first.pkl', 'rb'))\n",
    "# people_dict = pickle.load(open('../data/people_dict_half0.pkl', 'rb'))\n",
    "trans = {'video': 0, 'anchor_id': 1, 'path': 2, 'detail': 3, 'bbox': 4, 'gender':5, 'attributes': 6, 'feature': 7}\n",
    "hair_color_dict = pickle.load(open('../data/cloth/hair_color_NN.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hair_color_dict), len(cloth_dict), len(cloth_infer_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_anchor(video, anchor_person, people_dict):\n",
    "    FACE_SIM_THRESH = 0.9\n",
    "    OTHER_SHOW_THRESH = 85\n",
    "    date, station, show = get_detail_from_video_name(video)\n",
    "    ## find cluster center\n",
    "    for p in anchor_person:\n",
    "        if p['sim'] == 0:\n",
    "            anchor = p\n",
    "            break\n",
    "    ## find this anchor in other shows\n",
    "    cnt = 0\n",
    "    for show_check, people_list in people_dict.items():\n",
    "        if show != show_check:\n",
    "            for p in people_list:\n",
    "                dist = np.linalg.norm(p['feature'] - anchor['feature'])\n",
    "                if dist < FACE_SIM_THRESH:\n",
    "                    cnt += 1\n",
    "                    break\n",
    "    if cnt < OTHER_SHOW_THRESH:\n",
    "        return True\n",
    "    else:\n",
    "        print(video, cnt)\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Trump & Cliton\n",
    "cloth_dict_new = []\n",
    "for idx, cloth in enumerate(cloth_dict):\n",
    "    video = cloth[trans['video']]\n",
    "    anchor_id = cloth[trans['anchor_id']]\n",
    "    if clean_anchor(video, anchor_dict[video][anchor_id], people_dict):\n",
    "        cloth_dict_new.append(cloth)\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample & add hair color from NN\n",
    "cloth_dict_new = []\n",
    "np.random.seed(7777)\n",
    "for idx, cloth in enumerate(cloth_dict):\n",
    "    video = cloth[trans['video']]\n",
    "    anchor_id = cloth[trans['anchor_id']]\n",
    "    group = cloth_infer_group[idx]\n",
    "    choice = np.random.choice(len(group), 1)[0]\n",
    "    \n",
    "    assert(video == group[0][0] and video == hair_color_dict[idx][0])\n",
    "    assert(anchor_id == group[0][1] and anchor_id == hair_color_dict[idx][1])\n",
    "    \n",
    "    sample = group[choice]\n",
    "    path = sample[2]\n",
    "    feature = sample[5]\n",
    "    bbox = sample[3]\n",
    "    attributes = copy.deepcopy(cloth[trans['attributes']])\n",
    "    attributes.append(hair_color_dict[idx][2])\n",
    "    \n",
    "    new_cloth = copy.deepcopy(cloth)\n",
    "    new_cloth[trans['path']] = path\n",
    "    new_cloth[trans['feature']] = feature\n",
    "    new_cloth[trans['attributes']] = attributes\n",
    "    new_cloth[trans['bbox']] = bbox\n",
    "    cloth_dict_new.append(new_cloth)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cloth_dict_new, open('../data/cloth/newsAnchor_all_data_random.pkl', 'wb'), protocol=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
