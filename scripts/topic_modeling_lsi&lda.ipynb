{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "import pysrt\n",
    "import gensim\n",
    "import textacy\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transcripts and preprocess the text\n",
    "transcripts = []\n",
    "transcript_single = []\n",
    "\n",
    "for line in open('../data/test_video_list.txt'):\n",
    "    srt_name = line.replace('tvnews', '../data').replace('mp4', 'cc5.srt')[:-1]\n",
    "    offsets = []\n",
    "    transcript = ''\n",
    "    replace_list = ['\\n', '>', '.', ',', '?', '!', '\\'', '\"', '-', '(', ')']\n",
    "    #subs = pysrt.open(srt_name)\n",
    "    subs = pysrt.open('../data/videos/MSNBC_20110830_080000_The_Rachel_Maddow_Show.cc5.srt')\n",
    "    idx = 0\n",
    "    for sub in subs:\n",
    "        offsets.append((len(transcript), sub.start, sub.end))\n",
    "        text = sub.text\n",
    "        for token in replace_list:\n",
    "            text = text.replace(token, ' ')\n",
    "        transcript += text.upper() + ' '\n",
    "        if idx >= 10:\n",
    "            idx = 0;    \n",
    "            transcript_single.append(transcript)\n",
    "            transcript = ''\n",
    "        else:\n",
    "            idx += 1\n",
    "    transcripts.append((None, transcript, offsets))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract PROPN and NOUN using textacy\n",
    "# docs = [textacy.doc.Doc(transcript, lang=u'en', metadata={'offsets': offsets}) for (video, transcript, offsets) in transcripts]\n",
    "# corpus = textacy.Corpus(u'en', docs=docs)\n",
    "\n",
    "docs = [textacy.doc.Doc(transcript, lang=u'en') for transcript in transcript_single]\n",
    "corpus = textacy.Corpus(u'en', docs=docs)\n",
    "\n",
    "transcript_tokens = [\n",
    "    list(textacy.extract.words(doc, filter_nums=True, include_pos=['PROPN', 'NOUN'])) \n",
    "    for doc in corpus.docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dictionary and corpora using gensim\n",
    "transcript_tokens = [[str(token) for token in tokens if len(str(token)) > 1] for tokens in transcript_tokens]\n",
    "print(len(transcript_tokens))\n",
    "dictionary = gensim.corpora.Dictionary(transcript_tokens)\n",
    "print(dictionary)\n",
    "\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in transcript_tokens]\n",
    "#print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic extraction\n",
    "# step 1 -- initialize a model\n",
    "tfidf = gensim.models.TfidfModel(corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 -- apply the transformation to a whole corpus\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "#for doc in corpus_tfidf:\n",
    "#    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 -- # initialize an LSI transformation\n",
    "lsi = gensim.models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=20) \n",
    "corpus_lsi = lsi[corpus_tfidf]\n",
    "\n",
    "lsi.print_topics(20)\n",
    "\n",
    "#for doc in corpus_lsi: # both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
    "#    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 -- # initialize an Random Projection transformation\n",
    "#rp = gensim.models.RpModel(corpus_tfidf, id2word=dictionary, num_topics=100) \n",
    "#corpus_rp = rp[corpus_tfidf]\n",
    "\n",
    "lda = gensim.models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=20) \n",
    "corpus_lda = lda[corpus_tfidf]\n",
    "\n",
    "\n",
    "# hdp = gensim.models.HdpModel(corpus_tfidf, id2word=dictionary) \n",
    "# corpus_hdp = hdp[corpus_tfidf]\n",
    "\n",
    "lda.print_topics(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
